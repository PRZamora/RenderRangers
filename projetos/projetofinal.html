<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projeto Final - Render Rangers - Eye Tracking</title>
    <link rel="shortcut icon" href="../arquivo/imagens/miscelanious/favicon.ico">
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f4f4f4;
            color: #333;
        }
        header {
            background-color: #4CAF50;
            color: white;
            padding: 15px;
            text-align: center;
            border-top-left-radius: 15px;
            border-top-right-radius: 15px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        h1 {
            margin: 0;
            font-size: 2.5em;
            letter-spacing: 1.5px;
        }
        nav {
            background-color: #4CAF50;
            padding: 10px;
            text-align: center;
            border-bottom-left-radius: 15px;
            border-bottom-right-radius: 15px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        nav .dropdown {
            display: inline-block;
            position: relative;
            margin: 0 15px;
        }
        nav .dropdown button {
            background-color: #4CAF50;
            color: white;
            padding: 12px 25px;
            font-size: 16px;
            border: none;
            cursor: pointer;
            border-radius: 5px;
            transition: background-color 0.3s ease;
        }
        nav .dropdown button:hover {
            background-color: #45a049;
        }
        nav .dropdown-content {
            display: none;
            position: absolute;
            background-color: white;
            min-width: 160px;
            box-shadow: 0px 8px 16px rgba(0,0,0,0.2);
            z-index: 1;
            border-radius: 5px;
            top: 100%;
        }
        nav .dropdown:hover .dropdown-content {
            display: block;
        }
        nav .dropdown-content a {
            color: black;
            padding: 12px 16px;
            text-decoration: none;
            display: block;
            border-bottom: 1px solid #ddd;
            transition: background-color 0.3s ease;
        }
        nav .dropdown-content a:hover {
            background-color: #f1f1f1;
        }
        .container {
            display: flex;
            flex-grow: 1;
            margin-top: 30px;
        }
        .sidebar {
            position: fixed;
            top: 180px;
            left: 20px;
            width: 250px;
            background-color: #4CAF50;
            padding: 15px;
            border-top-left-radius: 15px;
            border-top-right-radius: 15px;
            border-bottom-left-radius: 15px;
            border-bottom-right-radius: 15px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            z-index: 10;
        }
        .sidebar ul {
            list-style-type: none;
            padding: 0;
        }
        .sidebar ul li {
            padding: 10px;
            cursor: pointer;
            border-bottom: 1px solid #ddd;
            color: white;
        }
        .sidebar ul li:hover {
            background-color: #45a049;
            color: white;
        }
        .content-wrapper {
            margin-left: 300px;
            padding: 20px;
            flex-grow: 1;
            overflow-y: auto;
        }
        .section {
            display: none;
            margin-bottom: 40px;
        }
        .section h2 {
            color: #4CAF50;
            margin-bottom: 40px;
        }
        .sub_section h3 {
            color: #4CAF50;
            margin-bottom: 8px;
        }
        footer {
            margin-top: 40px;
            text-align: center;
            color: #777;
        }
        footer p {
            margin: 10px 0;
        }
        .caret {
            display: inline-block;
            margin-left: 5px;
            width: 0;
            height: 0;
            border-left: 5px solid transparent;
            border-right: 5px solid transparent;
            border-top: 5px solid white;
        }
        button:hover .caret {
            border-top-color: #ddd;
        }
        a {
            color: #4CAF50;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
    </style>
    <script>
        // Função para obter o valor de um parâmetro na URL
        function getUrlParameter(name) {
            const urlParams = new URLSearchParams(window.location.search);
            return urlParams.get(name);
        }

        // Função para exibir a seção com base no id
        function showSection(id) {
            const sections = document.querySelectorAll('.section');
            sections.forEach(section => {
                section.style.display = 'none';
            });
            document.getElementById(id).style.display = 'block';
        }

        window.onload = () => {
            const sectionId = getUrlParameter('session'); // Obtém o parâmetro "session" da URL
            if (sectionId) {
                showSection(sectionId); // Exibe a seção correspondente
            } else {
                showSection('parte1'); // Exibe a seção 'parte6' por padrão
            }
        }
    </script>
</head>
<body>

<header>
    <h1>Projeto Final - Render Rangers - Eye Tracking</h1>
</header>

<nav>
    <div class="dropdown">
        <button>Relatórios <span class="caret"></span></button>
        <div class="dropdown-content">
            <a href="../relatorios/relatorio1.html">Relatório 1</a>
            <a href="../relatorios/relatorio2.html">Relatório 2</a>
            <a href="../relatorios/relatorio3.html">Relatório 3</a>
            <a href="../relatorios/relatorio4.html">Relatório 4</a>
            <a href="../relatorios/relatorio5.html">Relatório 5</a>
            <a href="../relatorios/relatorio6.html">Relatório 6</a>
            <a href="../relatorios/relatorio7.html">Relatório 7</a>
            <a href="../relatorios/relatorio8.html">Relatório 8</a>
        </div>
    </div>
    <div class="dropdown">
        <button>Projetos <span class="caret"></span></button>
        <div class="dropdown-content">
            <a href="projetofinal.html">Projeto Final</a>
        </div>
    </div>
    <div class="dropdown">
        <button>Membros <span class="caret"></span></button>
        <div class="dropdown-content">
            <a href="../apresentacao/joaopsl.html">João Pedro</a>
            <a href="../apresentacao/renatopod.html">Renato</a>
            <a href="../apresentacao/pedrorz.html">Pedro</a>
        </div>
    </div>
</nav>

<div class="container">
    <div class="sidebar">
        <ul>
            <li onclick="showSection('parte1')">Parte 1: Contexto e Cenário de Aplicação (CA)</li>
            <li onclick="showSection('parte2')">Parte 2: Modelagem Funcional do Sistema de Processamento Visual (MF)</li>
            <li onclick="showSection('parte3')">Parte 3: Desenvolvimento do Sistema de Processamento Visual (SPV)</li>
            <li onclick="showSection('parte4')">Parte 4: Elaboração de Laboratório Experimental do SPV (LEx)</li>
            <li onclick="showSection('parte5')">Parte 5: Teste de Campo do SPV (TC)</li>
            <li onclick="showSection('parte6')">Parte 6: Relatório Final</li>
            <li onclick="showSection('parte7')">Parte 7: Anexos</li>
        </ul>
    </div>

    <div class="content-wrapper">
        <div class="section" id="parte1">
            <h2>1. Contexto e Cenário de Aplicação (CA)</h2>
 
            <section>
                <h3>Contexto e Justificativa</h3>
                <p>O trabalho propõe o um sistema simplificado de Eye-Tracking (rastreamento ocular) para auxiliar pessoas que perderam a grande maioria dos movimentos do corpo porém possuem os olhos como forma de comunicação. Este sistema visa proporcionar mínima capacidade de comunicação, permitindo respostas simples a perguntas binárias ("Sim" ou "Não") com base na direção do olhar.</p>
                <p>Esse cenário clínico pode ser visto em um episódio da série médica <b>House M.D.</b>:</p>
                <iframe width="420" height="315" src="https://www.youtube.com/embed/cvsGOAxpajA"> </iframe>
            </section>

            <section>
                <h3>Objetivo do Sistema</h3>
                <p>Criar um sistema de processamento visual capaz de identificar movimento nos olhos e interpretá-lo como uma resposta binária. Os principais objetivos incluem:</p>
                <ul>
                    <li><strong>Detecção do Olho:</strong> Identificar e rastrear a movimento dos olhos.</li>
                    <li><strong>Comunicação de Respostas:</strong> Associar tais movimentos a respostas "Sim" ou "Não".</li>
                    <li><strong>Interface:</strong> Fornecer a um terceiro interface visual que exiba a resposta detectada.</li>
                </ul>
            </section>

            <section>
                <h3>Ações Realizadas pelo Programa</h3>
                <ul>
                    <li><strong>Rastreamento Ocular:</strong> Uso de algoritmos pré-implementados na lib OpenCV para localizar e seguir a posição da pupila.</li>
                    <li><strong>Detecção de Direção:</strong> Analisar se o olhar do usuário está direcionado para a esquerda ou direita.</li>
                    <li><strong>Exibição do Resultado:</strong> Mostrar "Sim" ou "Não" em uma tela com letras grandes e claras para permitir a comunicação.</li>
                </ul>
            </section>

            <section>
                <h3>Interatividade Prevista</h3>
                <p><strong>Usuário:</strong> Direciona o olhar para a esquerda ou direita para indicar uma resposta.</p>
                <p><strong>Sistema:</strong> Processa os dados visuais e exibe a resposta correspondente em near-real time, contando com um atraso para debounce.</p>
            </section>

            <section>
                <h3>Benefícios</h3>
                <ul>
                    <li><strong>Simplicidade:</strong> Focado exclusivamente na comunicação binária para simplificar usabilidade.</li>
                    <li><strong>Custo-baixo:</strong> Utiliza hardware barato, como webcams convencionais, e software de código aberto (OpenCV).</li>
                    <li><strong>Usabilidade:</strong> Interface simplificada, fácil de interpretar tanto para o usuário quanto para o interlocutor.</li>
                </ul>
            </section>

            <section>
                <h3>Conclusão</h3>
                <p>O sistema proposto proporciona uma solução direta de comunicação, buscando atender necessidades básicas de indivíduos com limitações motoras graves para oferecer, além de autonomia mínima, um pouco de dignidade.</p>
            </section>

        </div>

        <div class="section" id="parte2">
            <h2>2. Modelagem Funcional do Sistema de Processamento Visual (MF)</h2>
            
                <section>
                    <h3>Descrição Geral</h3>
                    <p>O sistema de eye-tracking permite a comunicação através de respostas "Sim" ou "Não" com base na direção do olhar (direita ou esquerda). O programa opera em tempo real utilizando a webcam e algoritmos de processamento de vídeo para identificar a pupila e traduzir seus movimentos em respostas.</p>
                </section>
            
                <section>
                    <h3>Funcionalidades Principais</h3>
                    <ul>
                        <li><strong>Aquisição de Imagem:</strong> Captura de quadros em tempo real a partir de webcam.</li>
                        <li><strong>Detecção de Rostos e Olhos:</strong> Localização para limitar a área de busca da pupila.</li>
                        <li><strong>Rastreamento Ocular:</strong> Identifica a posição e determina o movimento das pupilas.</li>
                        <li><strong>Interpretação do Movimento:</strong> Classifica o movimento em <b>Sim</b> ou <b>Não</b>.</li>
                        <li><strong>Feedback Visual:</strong> Exibe resposta na tela em near-real time para usuário e terceiros.</li>
                    </ul>
                </section>
            
                <section>
                    <h3>Fluxo de Dados do Sistema</h3>
                    <ul>
                        <li><strong>Entrada:</strong>
                            <ul>
                                <li>Imagens capturadas por webcam, em sua resolução nativa.</li>
                            </ul>
                        </li>
                        <li><strong>Processamento:</strong>
                            <ul>
                                <li>Conversão para escala de cinza para processamentos.</li>
                                <li>Detecção de rosto e/ou olhos usando classificador Cascade Haar.</li>
                                <li>Localização das pupilas ou íris dentro da região dos olhos.</li>
                                <li>Rastreamento da pupila e cálculo de sua posição relativa.</li>
                                <li>Interpretação do movimento ocular.</li>
                            </ul>
                        </li>
                        <li><strong>Saída:</strong>
                            <ul>
                                <li>Exibição da resposta "Sim" ou "Não".</li>
                            </ul>
                        </li>
                    </ul>
                </section>
            
                <section>
                    <h3>Componentes do Sistema</h3>
                    <ul>
                        <li><strong>Módulo de Captura:</strong>
                            <ul>
                                <li>Captura de imagens em tempo real com baixa latência.</li>
                            </ul>
                        </li>
                        <li><strong>Módulo de Processamento de Vídeo:</strong>
                            <ul>
                                <li>Aplicação de filtros, equalização de histograma.</li>
                                <li>Detecção de regiões.</li>
                                <li>Extração de características da pupila para leitura do movimento.</li>
                            </ul>
                        </li>
                        <li><strong>Módulo de Decisão:</strong>
                            <ul>
                                <li>Classificação da direção ocular em "Esquerda" ou "Direita".</li>
                            </ul>
                        </li>
                        <li><strong>Módulo de Exibição:</strong>
                            <ul>
                                <li>Exibe o resultado interpretado, traduzindo-o para "Sim" ou "Não".</li>
                            </ul>
                        </li>
                    </ul>
                </section>
            
                <section>
                    <h3>Diagrama - Versão Textual</h3>
                    <p><strong>Entrada:</strong> Webcam →</p>
                    <p><strong>Processamento:</strong> Captura de imagem → Conversão para escala de cinza → Detecção de rosto (opcional) → Detecção de olhos → Rastreamento de pupila → Interpretação do movimento.</p>
                    <p><strong>Saída:</strong> Exibição do resultado na interface visual.</p>
                </section>
            
                <section>
                    <h3>Considerações de Implementação</h3>
                    <ul>
                        <li><strong>Tolerância ao Ruído:</strong> Utilizar filtros para minimizar interferências externas e características do sensor da webcam.</li>
                        <li><strong>Interface Intuitiva:</strong> Letras grandes e cores fortes para facilitar leitura.</li>
                    </ul>
                </section>
            
                <section>
                    <h3>Resultado Esperado</h3>
                    <p>Um sistema suficientemente funcional que traduza movimentos dos olhos em respostas "Sim" ou "Não".</p>
                </section>

        </div>

        <div class="section" id="parte3">
            <h2>3. Desenvolvimento do Sistema de Processamento Visual (SPV)</h2>

            <section>
                <h3>Descrição</h3>
                <p>O código deste SPV é desenvolvido em linguagem C++ utilizando a lib de código-aberto OpenCV para realizar o processamento de vídeo. Conforme requisitado pelas orientações do professor, na versão atual do código, atende aos requisitos de:</p>
                <ul>
                    <li><strong>[Mandatório] Filtragem de Imagens:</strong> Aplicando filtros para reduzindo ruídos e destacar regiões de interesse.</li>
                    <li><strong>[Mandatório] Processamento de Cores:</strong> Convertendo para escala de cinza.</li>
                    <li><strong>[Mandatório] Histograma e Equalização:</strong> Equalizando o histograma da escala de cinzas.</li>
                    <li><strong>[Mandatório] Subtração de Fundo:</strong> Destacando os olhos do quadro.</li>
                    <li><strong>[Opcional] Detecção de Objetos:</strong> Detectando rostos e olhos para rastreamento via Haars Cascade.</li>
                </ul>
            </section>
        
            <section>
                <h3>Funcionalidades Implementadas</h3>
                <ul>
                    <li>Captura de vídeo em tempo real via webcam.</li>
                    <li>Detecção de rostos e olhos para restringir a área de busca.</li>
                    <li>Identificação do movimento de íris ou pupila (esquerda/direita).</li>
                    <li>Exibição de respostas binárias ("Sim" ou "Não") em uma interface mínima.</li>
                </ul>
            </section>
        
            <section>
                <h3>Código Fonte</h3>
                <p>O código fonte aqui apresentado é um espelho do desenvolvimento até a data do dia 28/Nov, conforme requisitado:</p>
                 
                <div style="background-color: #e8f0fe; padding: 15px; border-radius: 5px; margin: 10px 0; border-left: 5px solid #4CAF50;">
                    <p><strong>Nome do Script:</strong> eyeTracking.cpp</p>
                    <!-- Carregado nas tags de script abaixo -->
                    <pre><code id="code-snipet-1"></code></pre>
                </div>

            </section>

            <script>fetch("../arquivo/codigos/projeto/entrega_1/eyeTracking.cpp").then(response => response.text()).then(data => {document.getElementById("code-snipet-1").textContent = data;}).catch(error => console.error("Error loading code!", error));</script>            

            <section>
                <h3>Execução</h3>
                <ul>
                    <li><strong>Sistema Operacional:</strong> Foi validada compilação em Ubuntu-Linux e Windows.</li>
                    <li><strong>Dependências:</strong> OpenCV, máquina com suporte a webcam.</li>
                    <li><strong>Chamada do programa (Linux, construído via make):</strong>
                        <pre><code>./eyeTracking</code></pre>
                    </li>
                    <li><strong>Chamada do programa (Windows, construído via msbuild):</strong>
                        <pre><code>./Debug/eyeTracking.exe</code></pre>
                        <p>ou</p>
                        <pre><code>./Release/eyeTracking.exe</code></pre>
                    </li>
                </ul>
            </section>
        
            <section>
                <h3>Resultados Esperados</h3>
                <p>O sistema exibirá em near-real time uma interface com as respostas "Sim" ou "Não", baseando-se na direção do movimento dos olhos.</p>
            </section>

        </div>

        <div class="section" id="parte4">
            <h2>4. Elaboração de Laboratório Experimental do SPV (LEx)</h2>

            <section>
                <h3>Roteiro Experimental</h3>
                <p>O presente roteiro experimental fornece orientações detalhadas para o uso do Sistema de Eye-Tracking, permitindo avaliar sua funcionalidade e coletar feedback dos participantes.</p>
            </section>

            <section>
                <h3>Introdução</h3>
                <p><b>O quê é o nosso sistema?</b></p>
                <ul>
                    <li>O sistema busca permitir comunicação através do simples movimento dos olhos!</li>
                    <li>Existem síndromes e sintomas que enfraquecem ou impossibilitam a grande maioria dos movimentos do corpo de uma pessoa. E se permitíssemos que essas pessoas usassem o movimento dos olhos para se comunicar?</li>
                    <li>É pra isso que construímos esse Rastreamento Ocular (Eye-Tracking): utilizando o movimento dos olhos, você vai poder nos responder "Sim" ou "Não"!</li>
                    <li>Recomendamos que o usuário remova o óculos, para identificações mais acuradas!</li>
                </ul>

                <p><b>O quê você precisa para fazer esse experimento?</b></p>
                <ul>
                    <li>Acesso ao seguinte código: <a href="">EyeTracking.cpp</a> ou ao seguinte compilado: <a href="https://github.com/PRZamora/RenderRangers/blob/main/arquivo/codigos/projeto/Debug/eyeTracking.exe">Windows</a> | <a href="https://github.com/PRZamora/RenderRangers/blob/main/arquivo/codigos/projeto/eyeTracking.exe">Linux</a>;</li>
                    <li>Uma câmera compatível com computadores (Webcam).</li>
                    <li>Computador com entrada USB e capacidade para rodar aplicações de processamento visual.</li>
                    <li>Ambiente bem iluminado para otimizar a precisão do rastreamento ocular.</li>
                </ul>
        
                <p><b>Tudo pronto? Vamos às orientações!</b></p>
            </section>

            <section>
                <h3>Procedimento Experimental</h3>
                <ol>
                    <li><b>Preparativos:</b></li>
                    <ul>
                        <li>Ligue o computador e conecte a webcam.</li>
                        <li>Baixe e execute o arquivo do sistema (<code>EyeTracking.exe</code>).</li>
                        <li>Certifique-se de que a webcam está ativa e o sistema está exibindo a interface corretamente.</li>
                    </ul>
        
                    <li><b>Posicionamento:</b></li>
                    <ul>
                        <li>Ajuste a webcam para iluminação frontal, evitando sombras sobre os olhos.</li>
                        <li>Garanta que a câmera e o rosto do usuário permaneçam estáticos.</li>
                    </ul>
        
                    <li><b>Execução do Experimento:</b></li>
                    <ul>
                        <li>Peça ao participante para olhar para a direita para indicar "Sim".</li>
                        <li>Solicite que olhe para a esquerda para indicar "Não".</li>
                        <li>Realize várias rodadas de perguntas para avaliar a precisão do sistema.</li>
                    </ul>
                </ol>
            </section>
        
            <section>
                <h3>Coleta de Resultados</h3>
                <p>Registre os dados durante o experimento, como:</p>
                <ul>
                    <li>Taxa de respostas corretas (número de "Sim" e "Não" interpretados corretamente).</li>
                    <li>Tempo médio (estimado) de resposta entre o movimento ocular e a exibição do resultado.</li>
                    <li>Observações qualitativas (ex.: estabilidade do rastreamento, alternância entre olhos, possíveis falhas).</li>
                </ul>
            </section>
        
            <section>
                <h3>Questionário</h3>
                <p>Solicite aos participantes que respondam a perguntas sobre a experiência:</p>
                <ul>
                    <li>Quais variáveis afetaram a usabilidade e/ou estabilidade do sistema?</li>
                    <li>Alinhar o rosto com a câmera elimina problemas de paralaxe?</li>
                    <li>A aplicação implementa 'debounce' para evitar mudanças repentinas. Você entende que o tempo seja adequado para comunicação?</li>
                    <li>Entendendo que foram registrados os resultados: quão instáveis foram os erros no reconhecimento ocular?</li>
                </ul>
            </section>
        
            <section>
                <h3>Feedback</h3>
                <p>Com base nos resultados e nas respostas do questionário, analise:</p>
                <ul>
                    <li>Pontos fortes do sistema (ex.: alta precisão, facilidade de uso).</li>
                    <li>Limitações observadas (ex.: dependência de iluminação, atraso nas respostas).</li>
                    <li>Sugestões de melhorias para futuras versões.</li>
                </ul>
            </section>

        </div>

        <div class="section" id="parte5">
            <h2>5. Teste de Campo do SPV (TC)</h2>
            <p>[ToDO]</p>
        </div>

        <div class="section" id="parte6">
            <h2>6. Relatório Final</h2>
            <p>[ToDO]</p>
                <div class="sub_section">
                    <h3>1. Introdução</h3>
                    <p>Os objetivos do trabalho eram:</p>
                    <ul>
                        <li>Enender e aplicar a subração de fundos em imagens, vídeos e em tempo real pela webcam.</li>
                        <li>Como aplicar isso em códigos de processamento de imagens utilizando o OpenCV.</li>
                    </ul>
                </div>
                
                <div class="sub_section">
                    <h3>2. Fundamentos Básicos</h3>
                    <p>Para a execução do laboratório foi necessário a utilização do programa OpenCV.</p>
                    <p>A técnica utilizada foi a Background Subtraction</p>
                </div>
            
                <div class="sub_section">
                    <h3>3. Materiais e Métodos</h3>
                    <p>- Diagrama de blocos funcional</p>
                    <p>- Ambiente detalhado dos experimentos (nome e versão dos sistemas, equipamentos, programas, bibliotecas, software utilizados)</p>
                    <p>- Procedimentos experimentais</p>
                </div>
            
                <div class="sub_section">
                    <h3>4. Resultados e Análises</h3>
                    <p>[Escreva a análise e observações dos resultados obtidos]</p>
                    <p>Mostre os efeitos causados nas imagens e nos sinais, além de observações próprias sobre os experimentos.</p>
                </div>
            
                <div class="sub_section">
                    <h3>5. Conclusões e Comentários Finais</h3>
                    <p>[Escreva as conclusões e comentários finais]</p>
                </div>
            </div>

        </div>

        <div class="section" id="parte7">
            <h2>7. Anexos e Outros materiais</h2>
            
            <p>Aqui podem ser encontrados materiais de referência, apresentação realizada, entre outros objetos.</p>

            <ul>
                <li>Apresentação: <a href="ToDo">Google Presentations</a></li>
                <li>Repositório desta documentação: <a href="https://github.com/PRZamora/RenderRangers">Github</a></li>
            </ul>



        </div>

    </div>
</div>

<footer>
    <p>&copy; 2024 Render Rangers | UFABC</p>
</footer>

</body>
</html>
